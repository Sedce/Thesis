{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "import lyricwikia\n",
    "\n",
    "print( lyricwikia.get_lyrics('Justin Bieber', 'Baby'))\n",
    "def get_tokens():\n",
    "    text = lyricwikia.get_lyrics('Justin Bieber', 'Baby')\n",
    "    lowers = text.lower()\n",
    "    #remove the punctuation using the character deletion step of translate\n",
    "    #no_punctuation = lowers.translate(None,string.punctuation)\n",
    "    #remove the enter/spaces \n",
    "    translation = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    no_enter =  re.sub(r\"\\\\n\",\" \", lowers)\n",
    "    no_punctuation = lowers.translate(translation)\n",
    "    tokens = nltk.word_tokenize(no_punctuation)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokens = get_tokens()\n",
    "#count = Counter(tokens)\n",
    "#print(count.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "#tokens = get_tokens()\n",
    "#filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "#count = Counter(filtered)\n",
    "#print(count.most_common(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tagged = nltk.pos_tag(tokens)\n",
    "#print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "#stemmer = PorterStemmer()\n",
    "#stemmed = stem_tokens(filtered, stemmer)\n",
    "#count = Counter(stemmed)\n",
    "#print (count.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "#get and weigh in the tagged words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get audio analysis from spotify and put it into an array\n",
    "Songs  = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I’m', 'sorry', 'it’s', 'my', 'fault']\n",
      "sorry\n",
      "fault\n",
      "2.1408648648648647\n",
      "4.291567567567568\n",
      "['Thank', 'you', 'it’s', 'all', 'thanks', 'to', 'you']\n",
      "thanks\n",
      "4.34\n",
      "['These', 'were', 'words', 'you', 'said', 'out', 'of', 'habit']\n",
      "words\n",
      "habit\n",
      "2.358479381443299\n",
      "4.593556701030929\n",
      "['Even', 'though', 'I', 'knew', 'you', 'were', 'struggling', 'too']\n",
      "knew\n",
      "struggling\n",
      "2.8690349075975354\n",
      "6.803737166324435\n",
      "['You', 'probably', 'think', 'I’m', 'a', 'fool']\n",
      "think\n",
      "5.98\n",
      "['If', 'I', 'say', 'that', 'things', 'are', 'hard', 'with', 'a', 'crying', 'face']\n",
      "hard\n",
      "crying\n",
      "face\n",
      "1.7025043680838672\n",
      "3.8345952242283055\n",
      "6.205259172976121\n",
      "['Will', 'it', 'really', 'get', 'better']\n",
      "really\n",
      "get\n",
      "better\n",
      "1.6422210888413835\n",
      "3.5118266361377275\n",
      "4.9264740160385445\n",
      "['If', 'I', 'cry', 'and', 'say', 'it', 'hurts', 'who', 'will', 'have', 'a', 'harder', 'time']\n",
      "cry\n",
      "hurts\n",
      "harder\n",
      "time\n",
      "1.9274876976000983\n",
      "3.1882451558811042\n",
      "4.442832416087395\n",
      "5.853478860840347\n",
      "['Everyone', 'will', 'be', 'fine']\n",
      "['Maybe', 'we', 'trapped', 'each', 'other']\n",
      "trapped\n",
      "3.91\n",
      "['Inside', 'our', 'own', 'misunderstandings']\n",
      "['No', 'you', 'don’t', 'understand', 'me']\n",
      "['Whenever', 'I', 'see', 'your', 'worried', 'eyes']\n",
      "see\n",
      "worried\n",
      "eyes\n",
      "2.1109813309651138\n",
      "3.9501805123848865\n",
      "6.0857092109581625\n",
      "['Baby', 'I’m', 'so', 'lonely', 'so', 'lonely']\n",
      "lonely\n",
      "lonely\n",
      "1.085\n",
      "2.17\n",
      "['I', 'feel', 'like', 'I’m', 'alone']\n",
      "feel\n",
      "like\n",
      "alone\n",
      "1.1486234372133253\n",
      "2.5968938222420257\n",
      "3.598149555736115\n",
      "['When', 'I', 'see', 'you', 'so', 'tired', 'I', 'worry']\n",
      "see\n",
      "tired\n",
      "worry\n",
      "2.1791395045632336\n",
      "3.1222425032594527\n",
      "4.56986962190352\n",
      "['that', 'I’m', 'baggage', 'to', 'you', 'that', 'I’m', 'too', 'much']\n",
      "['Baby', 'I’m', 'so', 'lonely', 'so', 'lonely']\n",
      "lonely\n",
      "lonely\n",
      "1.085\n",
      "2.17\n",
      "['I', 'feel', 'like', 'I’m', 'alone']\n",
      "feel\n",
      "like\n",
      "alone\n",
      "1.1486234372133253\n",
      "2.5968938222420257\n",
      "3.598149555736115\n",
      "['I', 'don’t', 'want', 'to', 'make', 'it', 'obvious', 'to', 'you']\n",
      "want\n",
      "make\n",
      "2.3435000000000006\n",
      "4.636000000000001\n",
      "['I’m', 'used', 'to', 'just', 'holding', 'it', 'in']\n",
      "used\n",
      "holding\n",
      "2.002017167381974\n",
      "5.235278969957081\n",
      "['Understand', 'me']\n",
      "['We’re', 'together', 'but', 'we’re', 'not', 'walking', 'together']\n",
      "['Loneliness', 'and', 'misery', 'the', 'difference', 'is', 'only', 'one', 'memory', '(Ooh)']\n",
      "misery\n",
      "one\n",
      "memory\n",
      "0.7233421003193687\n",
      "1.9632444110464022\n",
      "4.609752019537854\n",
      "['But', 'why', 'do', 'you', 'keep', 'trying', 'to', 'write', 'it', 'as', 'something', 'else']\n",
      "keep\n",
      "trying\n",
      "write\n",
      "1.560961484305613\n",
      "4.123346402963413\n",
      "5.973578190325586\n",
      "['Baby', 'I’m', 'so', 'lonely', 'so', 'lonely']\n",
      "lonely\n",
      "lonely\n",
      "1.085\n",
      "2.17\n",
      "['I', 'feel', 'like', 'I’m', 'alone']\n",
      "feel\n",
      "like\n",
      "alone\n",
      "1.1486234372133253\n",
      "2.5968938222420257\n",
      "3.598149555736115\n",
      "['I', 'don’t', 'want', 'to', 'make', 'it', 'obvious', 'to', 'you']\n",
      "want\n",
      "make\n",
      "2.3435000000000006\n",
      "4.636000000000001\n",
      "['I’m', 'used', 'to', 'just', 'holding', 'it', 'in']\n",
      "used\n",
      "holding\n",
      "2.002017167381974\n",
      "5.235278969957081\n",
      "['Understand', 'me']\n",
      "['Leave', 'me', 'alone']\n",
      "alone\n",
      "2.41\n",
      "['Baby', 'I’m', 'so', 'lonely', 'so', 'lonely']\n",
      "lonely\n",
      "lonely\n",
      "1.085\n",
      "2.17\n",
      "['I', 'feel', 'like', 'I’m', 'alone']\n",
      "feel\n",
      "like\n",
      "alone\n",
      "1.1486234372133253\n",
      "2.5968938222420257\n",
      "3.598149555736115\n",
      "['Baby', 'I’m', 'so', 'lonely', 'so', 'lonely']\n",
      "lonely\n",
      "lonely\n",
      "1.085\n",
      "2.17\n",
      "['I', 'feel', 'like', 'I’m', 'alone']\n",
      "feel\n",
      "like\n",
      "alone\n",
      "1.1486234372133253\n",
      "2.5968938222420257\n",
      "3.598149555736115\n",
      "['Still', 'I', 'don’t', 'wanna', 'hide', 'it', 'from', 'you']\n",
      "hide\n",
      "4.32\n",
      "['But', 'I’m', 'used', 'to', 'just', 'holding', 'it', 'in']\n",
      "used\n",
      "holding\n",
      "2.002017167381974\n",
      "5.235278969957081\n"
     ]
    }
   ],
   "source": [
    "import anew\n",
    "\n",
    "with open(\"C:/Users/Cedezmarie/Desktop/Thesis/Song-Lyrics/Kim Jonghyun/Lonely.txt\", 'r') as f:\n",
    "    content = f.readlines()\n",
    "import csv\n",
    "#print(content)\n",
    "with open('sentiment.csv', 'w') as csvfile:\n",
    "    sentiment_writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    sentiment_writer.writerow([\"Sentence\", \"FileName\",  \"Valence\", \"Arousal\"])\n",
    "    \n",
    "    for line in content:\n",
    "        line = line.replace(',','')\n",
    "        line = line.rstrip()\n",
    "        if line.strip():\n",
    "            line_to_word = line.split(\" \")\n",
    "            print(line_to_word)\n",
    "            sentiment_attributes = anew.sentiment(line_to_word)\n",
    "            sentiment_writer.writerow([line_to_word, sentiment_attributes['valence'], sentiment_attributes['arousal']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
